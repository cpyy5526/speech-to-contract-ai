import React, { useEffect, useRef, useState } from "react";
import "../styles/Recording.css";
import { useNavigate } from "react-router-dom";
import { initiateTranscription } from "../services/convertApiMock"; // ë°°í¬ ì‹œ convertApië¡œ


function Recording() {
  const [isRecording, setIsRecording] = useState(false);
  const [isStopped, setIsStopped] = useState(false);
  const [seconds, setSeconds] = useState(0);
  const [audioBlob, setAudioBlob] = useState(null);
  const mediaRecorderRef = useRef(null);
  const audioChunks = useRef([]);
  const navigate = useNavigate();

  useEffect(() => {
    let timer;
    if (isRecording) {
      timer = setInterval(() => setSeconds((s) => s + 1), 1000);
    }
    return () => clearInterval(timer);
  }, [isRecording]);

  useEffect(() => {
    startRecording();
  }, []);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream);
      mediaRecorderRef.current = recorder;

      recorder.ondataavailable = (e) => audioChunks.current.push(e.data);
      recorder.onstop = () => {
        const blob = new Blob(audioChunks.current, { type: "audio/webm" });
        setAudioBlob(blob);
        audioChunks.current = [];
      };

      recorder.start();
      setIsRecording(true);
      setIsStopped(false);
      setSeconds(0);
    } catch (err) {
      alert("ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”");
    }
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setIsRecording(false);
    setIsStopped(true);
  };

  const handleFinish = async () => {
    if (!audioBlob) return;

    try {
      const filename = `recording_${Date.now()}.webm`;
      const result = await initiateTranscription(filename);
      const uploadUrl = result.upload_url;

      console.log("âœ… ì—…ë¡œë“œ ì˜ˆì•½ ì™„ë£Œ:", uploadUrl);

      // Converting í˜ì´ì§€ë¡œ uploadUrl ì „ë‹¬
      navigate("/converting", { state: { uploadUrl, audioBlob } }); // audioBlobë„ í•¨ê»˜ ë„˜ê¸¸ ìˆ˜ ìˆìŒ
    } catch (err) {
      console.error("âŒ ì—…ë¡œë“œ ì˜ˆì•½ ì‹¤íŒ¨:", err);
      alert("ì—…ë¡œë“œ ì˜ˆì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
    }
  };



  return (
    <div className="recording-container">
      

      <div className="recording-content">
        <div className="listening-text">ë“£ëŠ” ì¤‘...</div>
        <div className="mic-section">
          <div className="mic-icon">ğŸ¤</div>
          <div className="timer">
            {String(Math.floor(seconds / 60)).padStart(2, "0")}:
            {String(seconds % 60).padStart(2, "0")}
          </div>
        </div>
      </div>

      {isStopped && audioBlob && (
          <div className="preview-section">
            <p>ë…¹ìŒ ë¯¸ë¦¬ ë“£ê¸°:</p>
            <audio controls src={URL.createObjectURL(audioBlob)} />
          </div>
      )}
      
      <div className="recording-buttons">
        {isRecording ? (
          <button className="stop-btn" onClick={stopRecording}>ğŸŸ¥ ë…¹ìŒ ì¤‘ë‹¨</button>
        ) : (
          <>
            {isStopped && (
              <>
                <button className="stop-btn" onClick={startRecording}>ğŸ” ì¬ì‹œì‘</button>
                <button className="finish-btn" onClick={handleFinish}>âœ… í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸°</button>
              </>
            )}
          </>
        )}
      </div>
    </div>
  );
}

export default Recording;
