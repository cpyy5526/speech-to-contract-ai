import React, { useEffect, useRef, useState } from "react";
import "../styles/Recording.css";
import { useNavigate } from "react-router-dom";
import { initiateTranscription } from "../services/convertApiMock"; // ë°°í¬ ì‹œ convertApië¡œ


function Recording() {
  const [isRecording, setIsRecording] = useState(false);
  const [isStopped, setIsStopped] = useState(false);
  const [seconds, setSeconds] = useState(0);
  const [audioBlob, setAudioBlob] = useState(null);
  const [mediaStream, setMediaStream] = useState(null);
  const mediaRecorderRef = useRef(null);
  const audioChunks = useRef([]);
  const navigate = useNavigate();

  useEffect(() => {
    let timer;
    if (isRecording) {
      timer = setInterval(() => setSeconds((s) => s + 1), 1000);
    }
    return () => clearInterval(timer);
  }, [isRecording]);

  useEffect(() => {
  startRecording();

  
  return () => {
    console.log("ğŸ§¹ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë§ˆì´í¬ ì •ë¦¬");

    if (mediaRecorderRef.current?.state === "recording") {
      mediaRecorderRef.current.stop();
    }

    if (window.streamsToClose) {
      window.streamsToClose.forEach((stream) => {
        stream.getTracks().forEach((track) => {
          console.log(" [cleanup] ì „ì—­ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ", track);
          track.stop();
        });
      });
      window.streamsToClose = [];
    }
  };
}, []);

  const startRecording = async () => {
  if (mediaStream) {
    console.log(" ì´ë¯¸ mediaStream ì¡´ì¬í•¨. ì¤‘ë³µ ë°©ì§€");
    return;
  }

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    // 
    window.streamsToClose = window.streamsToClose || [];
    window.streamsToClose.push(stream);

    const recorder = new MediaRecorder(stream);
    mediaRecorderRef.current = recorder;
    setMediaStream(stream);

    recorder.ondataavailable = (e) => audioChunks.current.push(e.data);
    recorder.onstop = () => {
      const blob = new Blob(audioChunks.current, { type: "audio/webm" });
      setAudioBlob(blob);
      audioChunks.current = [];
    };

    recorder.start();
    setIsRecording(true);
    setIsStopped(false);
    setSeconds(0);
  } catch (err) {
    alert("ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”");
  }
};


  const stopMediaStream = () => {
  if (mediaStream) {
    console.log("ğŸ›‘ ë§ˆì´í¬ íŠ¸ë™ ì¢…ë£Œ ì‹œë„:", mediaStream.getTracks());
    mediaStream.getTracks().forEach((track) => {
      console.log(`ğŸ§¨ ì¢…ë£Œ ì „ ìƒíƒœ: kind=${track.kind}, enabled=${track.enabled}, readyState=${track.readyState}`);
      track.stop();
      console.log(`âœ… ì¢…ë£Œ í›„ ìƒíƒœ: kind=${track.kind}, enabled=${track.enabled}, readyState=${track.readyState}`);
    });
    setMediaStream(null);
  } else {
    console.log("âš ï¸ ì¢…ë£Œí•  mediaStream ì—†ìŒ");
  }
};

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    stopMediaStream(); // ë§ˆì´í¬ ì¢…ë£Œ
    setIsRecording(false);
    setIsStopped(true);
  };

  const handleFinish = async () => {
    if (!audioBlob) return;
    const finalize = async () => {
      try {
        const filename = `recording_${Date.now()}.webm`;

        if (!filename || typeof filename !== "string" || filename.trim() === "") {
          alert("íŒŒì¼ëª…ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
          return;
        }

        const result = await initiateTranscription(filename);
        const uploadUrl = result.upload_url;

        // Converting í˜ì´ì§€ë¡œ uploadUrlê³¼ audioBlob ì „ë‹¬
        navigate("/converting", { state: { uploadUrl, audioBlob, filename } });
      } catch (err) {
        // ì—ëŸ¬ ì²˜ë¦¬ëŠ” authApiì—ì„œ ì²˜ë¦¬ë¨
      }
    }
  };





  return (
    <div className="recording-container">
      

      <div className="recording-content">
        <div className="listening-text">ë“£ëŠ” ì¤‘...</div>
        <div className="mic-section">
          <div className="mic-icon">ğŸ¤</div>
          <div className="timer">
            {String(Math.floor(seconds / 60)).padStart(2, "0")}:
            {String(seconds % 60).padStart(2, "0")}
          </div>
        </div>
      </div>

      {isStopped && audioBlob && (
          <div className="preview-section">
            <p>ë…¹ìŒ ë¯¸ë¦¬ ë“£ê¸°:</p>
            <audio controls src={URL.createObjectURL(audioBlob)} />
          </div>
      )}
      
      <div className="recording-buttons">
        {isRecording ? (
          <button className="stop-btn" onClick={stopRecording}>ğŸŸ¥ ë…¹ìŒ ì¤‘ë‹¨</button>
        ) : (
          <>
            {isStopped && (
              <>
                <button className="stop-btn" onClick={startRecording}>ğŸ” ì¬ì‹œì‘</button>
                <button className="finish-btn" onClick={handleFinish}>âœ… í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸°</button>
              </>
            )}
          </>
        )}
      </div>
    </div>
  );
}

export default Recording;
