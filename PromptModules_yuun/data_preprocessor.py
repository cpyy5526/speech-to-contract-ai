import os
import whisper
from pyannote.audio import Pipeline
import librosa
import soundfile as sf

from hanspell import spell_checker
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

from dotenv import load_dotenv, find_dotenv

# íŒŒì¼ ë¡œë“œ
def load_file(fs, nfile, create_dir=False):
    base_dir = os.path.dirname(os.path.abspath(__file__))  # í˜„ì¬ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ ê¸°ì¤€
    dir_path = os.path.join(base_dir, fs)
    path = os.path.join(dir_path, nfile)
    
    # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if create_dir and not os.path.exists(dir_path):
        os.makedirs(dir_path)
        print(f"ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")
    
    # ì½ê¸° ëª¨ë“œì—ì„œëŠ” íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not create_dir and not os.path.exists(path):
        raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {path}")
    
    return path

# í™”ì ë¶„ë¦¬ ë° ìŒì„± ì¶”ì¶œ ë§¤ì¹­
def diarized_transcription(audio_nfile, txt_nfile):
    audio_path=load_file("user_data", audio_nfile)
    txt_path = load_file("user_data", txt_nfile, create_dir=True)
    
    # 1. pyannote.audioë¡œ í™”ì ë¶„ë¦¬
    # í™”ìëŠ” ë‘ ëª…ìœ¼ë¡œ ì§€ì •
    # HUGGINGFACE_TOKEN
    _=load_dotenv(find_dotenv())
    hf_token= os.getenv("HUGGINGFACE_TOKEN")

    try:
        pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=hf_token)
    except Exception as e:
        raise RuntimeError(f"âŒ pyannote pipeline ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    diarization=pipeline(audio_path, num_speakers=2)
    
    # 2. ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ (ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œìš©)
    audio_data, sr = librosa.load(audio_path, sr=16000)
    
    # 3. Whisper ëª¨ë¸ ë¡œë“œ
    model=whisper.load_model("medium") 
     
    # 4. í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ê·¸ë£¹í™” ë° ë³‘í•©
    all_segments = []
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        all_segments.append({
            'start': turn.start,
            'end': turn.end,
            'speaker': speaker
        })
        
    all_segments.sort(key=lambda x:x['start'])
    
    # ì§§ì€ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ë³‘í•©í•˜ì—¬ ìŒì„± ì¸ì‹ ì •í™•ë„ í–¥ìƒ
    def merge_short_segments(segments, min_duration=1.0, max_gap=0.5):
        if not segments:
            return segments
        
        merged = []
        current_segment = segments[0].copy()
        
        for next_segment in segments[1:]:
            # ê°™ì€ í™”ìì´ê³ , ê°„ê²©ì´ ì‘ê³ , í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì§§ì€ ê²½ìš° ë³‘í•©
            gap = next_segment['start'] - current_segment['end']
            current_duration = current_segment['end'] - current_segment['start']
            
            if (current_segment['speaker'] == next_segment['speaker'] and 
                gap <= max_gap and 
                current_duration < min_duration):
                current_segment['end'] = next_segment['end']
            else:
                merged.append(current_segment)
                current_segment = next_segment.copy()
        merged.append(current_segment)
        
        return merged

    all_segments=merge_short_segments(all_segments, min_duration=1.0, max_gap=0.5)
    
    # 5. ê° í™”ìë³„ë¡œ ìŒì„± ì¸ì‹
    diarized_output = []
    
    for i, segment in enumerate(all_segments):
        start_time = segment['start']
        end_time = segment['end']
        speaker = segment['speaker']
        
        # ì‹œê°„ì„ ìƒ˜í”Œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)
            
        # ë²”ìœ„ ê²€ì¦
        start_sample = max(0, start_sample)
        end_sample = min(len(audio_data), end_sample)
            
        if start_sample >= end_sample:
            continue
        
        segment_audio = audio_data[start_sample:end_sample]
    
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (whisper ì…ë ¥ìš©)
        temp_audio_path = f"temp_segment_{i}_{speaker}.wav"
        sf.write(temp_audio_path, segment_audio, sr)
        
        try:
            # Whisperë¡œ ìŒì„± ì¸ì‹
            result = model.transcribe(temp_audio_path, language='ko')
            if result["segments"]:
                # ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
                ## ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹œê°„ ì •ë³´ëŠ” ì„ì‹œ íŒŒì¼ ê¸°ì¤€ì´ë¯€ë¡œ ë¶€ì •í™•í•¨
                full_text = result["text"].strip()
                if full_text:
                    diarized_output.append({
                        'speaker': speaker,
                        'text': full_text,
                        'start_time': start_time,
                        'end_time': end_time,
                        'duration': end_time - start_time
                    }) 
        except Exception as e:
            print(f"âš ï¸ {speaker} ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(temp_audio_path):
                os.remove(temp_audio_path)
    
    # 6. ê²°ê³¼ ì •ë ¬ ë° ì €ì¥ (ì²« ë²ˆì§¸ ë°œí™” ì‹œê°„ ê¸°ì¤€)
    diarized_output.sort(key=lambda x: x['start_time'])
                    
    # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    with open(txt_path, "w", encoding="utf-8") as f:
        for item in diarized_output:
            speaker = item['speaker']
            text = item['text']
            # í™”ìë³„ ë°œí™” ì‹œê°„ ì •ë³´ í¬í•¨
            f.write(f"{speaker}: {text}\n")
            
            
# nltk ë¶ˆìš©ì–´ ë‹¤ìš´ë¡œë“œ
## nltkëŠ” í•œêµ­ì–´ ë¶ˆìš©ì–´ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
## ë”°ë¡œ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ txt íŒŒì¼ë¡œ ì§€ì •í•´ë‘ 
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
def text_preprocess(input_txt_nfile, output_txt_nfile, stopwords_nfile):
    def load_stopwords_from_file(nfile):
        sw_path = load_file("stopwords", nfile)
        
        with open(sw_path, 'r', encoding='utf-8') as f:
            stopwords_list = [line.strip() for line in f if line.strip()]
        return set(stopwords_list)

    # ë¶ˆìš©ì–´ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    stop_words = load_stopwords_from_file(stopwords_nfile)
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ (user_data ë””ë ‰í† ë¦¬ì—ì„œ ì½ê¸°)
    input_path = load_file("user_data", input_txt_nfile)
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (user_data ë””ë ‰í† ë¦¬ì— ì €ì¥)
    output_path = load_file("user_data", output_txt_nfile, create_dir=True)
    
    with open(input_path, "r", encoding="utf-8") as f:
        original_text = f.read()
        
    # ë§ì¶¤ë²• êµì •
    ### KeyError ì˜ˆì™¸ ì²˜ë¦¬ ë° í° í…ìŠ¤íŠ¸ ë¶„í•  ì²˜ë¦¬
    try:
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
        chunk_size = 500  # í•œ ë²ˆì— ì²˜ë¦¬í•  ìµœëŒ€ ê¸€ì ìˆ˜
        chunks = [original_text[i:i+chunk_size] for i in range(0, len(original_text), chunk_size)]
        
        corrected_chunks = []
        for chunk in chunks:
            try:
                # ê° ì²­í¬ì— ëŒ€í•´ ë§ì¶¤ë²• ê²€ì‚¬ ìˆ˜í–‰
                corrected_chunk = spell_checker.check(chunk)
                corrected_chunks.append(corrected_chunk.checked)
            except KeyError:
                # KeyErrorê°€ ë°œìƒí•˜ë©´ ì›ë˜ ì²­í¬ë¥¼ ì‚¬ìš©
                print(f"ë§ì¶¤ë²• ê²€ì‚¬ ì¤‘ KeyError ë°œìƒ, ì›ë¬¸ ì‚¬ìš©: {chunk[:30]}...")
                corrected_chunks.append(chunk)
            except Exception as e:
                # ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
                print(f"ë§ì¶¤ë²• ê²€ì‚¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                corrected_chunks.append(chunk)
                
        corrected = ' '.join(corrected_chunks)
    except Exception as e:
        print(f"ë§ì¶¤ë²• ê²€ì‚¬ ì „ì²´ ê³¼ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        corrected = original_text  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
    
    # ë¶ˆìš©ì–´ ì œê±°
    ## words_tokenìœ¼ë¡œ ë³€ê²½ í•˜ì—¬ í† í°í™”
    word_tokens=word_tokenize(corrected)
    filtered = [word for word in word_tokens if word not in stop_words]
    processed_text = " ".join(filtered)
    
    # ê²°ê³¼ ì €ì¥
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(processed_text)
        

def data_preprocess(): 
    # audio_nfile = "audio_input.wav"
    audio_nfile = "test_audio.wav"
    diarized_txt_nfile= "diarized_output.txt"
    processed_txt_nfile= "processed_output.txt"
    stopwords_nfile="korean_stopwords.txt"
    
    try:
        # ì˜¤ë””ì˜¤ ë³€í™˜
        print("ğŸµ ìŒì„± ì¸ì‹ ë° í™”ì ë¶„ë¦¬ ì‹œì‘...")
        diarized_transcription(audio_nfile, diarized_txt_nfile)
        print("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ")
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        print("ğŸ“ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì‹œì‘...")
        text_preprocess(diarized_txt_nfile, processed_txt_nfile, stopwords_nfile)
        print("âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì™„ë£Œ")
        
        # ì¤‘ê°„ íŒŒì¼ ì •ë¦¬
        if os.path.exists(load_file("user_data", diarized_txt_nfile)):
            os.remove(load_file("user_data", diarized_txt_nfile))
            print("ğŸ—‘ï¸ ì¤‘ê°„ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        # if os.path.exists(load_file("user_data", audio_nfile)):
        #     os.remove(load_file("user_data", audio_nfile))
        #     print("ğŸ—‘ï¸ ì¤‘ê°„ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        
        print("ğŸ‰ ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")