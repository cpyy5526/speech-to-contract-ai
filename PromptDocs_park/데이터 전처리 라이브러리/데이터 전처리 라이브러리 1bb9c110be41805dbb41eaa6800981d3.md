# 데이터 전처리 라이브러리

## 음성 녹음 파일 → 텍스트 변환 → GPT API에 입력

이 과정에서 녹음파일을 변환한 텍스트 파일을 그대로 GPT API에 입력으로 주면 불필요한 단어(추임새, 감탄사 등), 공백 을 제거하지 못한 채로 입력되기 때문에 토큰 최적화나 결과의 정확도 측면에서 문제가 있을수 있다.

따라서 이 텍스트 파일을 전처리 해주는 과정이 필요하다.

우리가 사용할 Whisper가 출력하는 결과값에는 다음과 같은 문제가 발생 할 수 있다.

1. 한국어 띄어쓰기 미흡
2. 맞춤법 수정 필요
3. 화자 분리가 안됨
4. 전문용어(잘 사용하지 않는 단어)를 캐치 못할 수 있음
5. 불필요한 단어

1번과 2번, 3번은 데이터 전처리 라이브러리를 통해 해결

---

### 1번과 2번의 경우 사용가능한 라이브러리

- 한국어 경우
    - py-hanspell - 네이버 맞춤법 검사기를 활용
        
        ```python
        from hanspell import spell_checker
        text = "안녕하세요.오늘 날씨가좋네요"
        result = spell_checker.check(text)
        print(result.checked)  # "안녕하세요. 오늘 날씨가 좋네요."
        ```
        
    - soynlp - 한국어 띄어쓰기 교정기능
        
        ```python
        from soynlp.normalizer import spaced
        print(spaced("안녕하세요오늘날씨가좋네요"))  # "안녕하세요 오늘 날씨가 좋네요"
        ```
        
    - PyKoSpacing - 한국어 띄어쓰기 교정 기능
        
        ```python
        from pykospacing import spacing
        
        new_sent = sent.replace(" ", '') # 띄어쓰기가 없는 문장으로 만들기
        print(new_sent)
        ```
        
- 영어의 경우
    - gramformer - 문법 교정
        
        ```python
        from gramformer import Gramformer
        
        gf = Gramformer(models=1)  # 1: Corrector model
        text = "This are not making sense."
        corrected_text = gf.correct(text)
        print(corrected_text)  # "This is not making sense."
        ```
        
    - textblob- 문법 및 자연스러운 문장 변환
        
        ```python
        from textblob import TextBlob
        
        text = "This are not correct."
        blob = TextBlob(text)
        print(blob.correct())  # "This is not correct."
        ```
        

---

### 화자 분리를 위한 라이브러리

- pyannote-audio - 화자 분리 기능을 제공
    
    ```python
    from pyannote.audio.pipelines.speaker_diarization import SpeakerDiarization
    from pyannote.core import Segment
    
    pipeline = SpeakerDiarization.from_pretrained("pyannote/speaker-diarization")
    diarization = pipeline("audio.wav")
    
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        print(f"Speaker {speaker}: {turn.start:.1f}s - {turn.end:.1f}s")
    
    ```
    
- WhisperX - 시간 정보와 화자 분리 기능
    
    ```python
    import whisperx
    
    model = whisperx.load_model("large-v2", device="cuda")
    audio = whisperx.load_audio("audio.wav")
    result = model.transcribe(audio, batch_size=16)
    
    # 화자 분리 적용
    diarize_model = whisperx.DiarizationPipeline(device="cuda")
    diarization_result = diarize_model(audio)
    
    # 결과 출력
    for segment in result["segments"]:
        speaker = diarization_result.get(segment["start"], segment["end"])
        print(f"Speaker {speaker}: {segment['text']}")
    
    ```
    
- WebRTC VAD - 화자 분리 기능을 제공

이중 pyannote 와 Whisper X를 활용한 블로그가 있어 첨부

[[Whisper|Pyannote] 상담사 통화녹음 화자분리](https://youngseo-computerblog.tistory.com/120)

해당 블로그를 보면 데이터 변환 과정에서 노이즈가 제거된다는 것을 알수 있다. 
일단 우리 프로젝트에서도 이와 같은 방식으로 진행 해보고 노이즈가 제거가 되지 않는다면 이후 다른 방법을 찾아보자

---

### 불필요한 단어제거 및 요약

기본적으로 re (정규식 표현), nltk를 활용하면 불필요한 단어는 제거된다고 함.

요약은 LLM을 사용해야한다.

만약 계약서 작성에 잘 요약된 텍스트 본이 좋은 계약서를 만들어 준다고 한다면 성능이 좋은 LLM인 GPT API를 중간에 한번 더 거쳐서 요약하는 것이 하나의 방법일 것이다.

whisper로 텍스트 변환 → GPT API 로 요약 → GPT API로 계약서 생성

아니면 요약이 있으면 좋은데 잘 요약한거랑 차이가 없다면 비용이 무료인 Hugging face 의 T5나 BART(한국어의 경우 koT5 또는 KoBART)를 사용하면 될듯하다.

whisper로 텍스트 변환 → T5/BART 로 요약 → GPT API로 계약서 생성

혹은 요약을 하면 결과가 잘 나오지 않는 경우

whisper로 텍스트 변환 → GPT API로 계약서 생성

---

## 결론

모든 언어에 맞춘 전처리 라이브러리는 특정언어 전처리가 잘 동작하지 않을 수 있다.

따라서 각 언어에 맞춘 라이브러리를 하나씩 사용하는게 좋다.

한국어의 경우

- 맞춤법 및 띄어쓰기 - py-hanspell
- 요약 - KoT5

영어의 경우 

- 문법 검사 - gramformer
- 요약 - GPT 또는 T5

공통

- 불필요한 단어제거 - re, nltk
- 화자 분리 - pyannote 와 whisperX